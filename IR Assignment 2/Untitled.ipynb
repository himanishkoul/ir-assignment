{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e94dc791-7b8e-432b-a8a4-e91fa3b6f758",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your search query:  to see if your restaurant already has a listing on Zomato. If you find it, you’ll start with claiming your restaurant. Otherwise, you’ll begin by creating a new listing instead.  1. Claim or Start Your Listing  First, visit Zomato’s business homepage to search for your restaurant. If you can’t find your listing you can add a restaurant here. Make sure you’re on the business search page and not the user-facing search engine.  If your listing is in Zomato and unclaimed, you will see the option to claim it with a green button. If it’s already claimed, you will need to track down the owner of the page or contact Zomato for help.  Filippi's Pizza Grotto in Little Italy has not yet claimed their listing. If you were the restaurant owner, you would click the green outlined \"Claim this restaurant\" button.  In order to claim your listing, you’ need verification that you are the owner or manager of the business. Zomato asks for a document of proof, like your certificate of registration. A representative from Zomato will then follow-up with you to confirm ownership and assist you with the next steps.  Once you’ve submitted your proof of ownership, Zomato will verify your claim by sending an SMS message to the phone number you provided. Add this code on Zomato’s website to finish up your claim.  2. Set Up Your Business Owner Account\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top 10 relevant documents:\n",
      "zomato.txt: 0.933279770682370\n",
      "swiggy.txt: 0.272265286132856\n",
      "reddit.txt: 0.211260876771811\n",
      "google.txt: 0.189137133951502\n",
      "bing.txt: 0.175068387563053\n",
      "whatsapp.txt: 0.158757256384313\n",
      "messenger.txt: 0.152372905486089\n",
      "yahoo.txt: 0.147460471037912\n",
      "skype.txt: 0.122323820323397\n",
      "telegram.txt: 0.112197473772053\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "# Initialize global variables\n",
    "dictionary = defaultdict(list)\n",
    "doc_lengths = {}\n",
    "docID_to_filename = {}\n",
    "N = 0  # Total number of documents\n",
    "\n",
    "# Indexing phase\n",
    "def index_corpus(corpus_path):\n",
    "    global N\n",
    "    for docID, filename in enumerate(os.listdir(corpus_path)):\n",
    "        docID_to_filename[docID] = filename  # Store filename for later use\n",
    "        N += 1\n",
    "        with open(os.path.join(corpus_path, filename), 'r', encoding='utf-8') as file:\n",
    "            content = file.read().lower().split()  # Basic tokenization\n",
    "            term_freqs = defaultdict(int)\n",
    "            # Calculate term frequencies\n",
    "            for term in content:\n",
    "                term_freqs[term] += 1\n",
    "            \n",
    "            # Update dictionary and postings\n",
    "            for term, tf in term_freqs.items():\n",
    "                dictionary[term].append((docID, tf))\n",
    "                \n",
    "            # Calculate and store document length\n",
    "            length = math.sqrt(sum((1 + math.log10(tf)) ** 2 for tf in term_freqs.values()))\n",
    "            doc_lengths[docID] = length\n",
    "\n",
    "# Query phase\n",
    "def process_query(query):\n",
    "    query_terms = query.lower().split()  # Basic tokenization\n",
    "    query_weights = defaultdict(float)\n",
    "    \n",
    "    # Calculate tf-idf for query with boosted weights\n",
    "    query_length = 0\n",
    "    for term in query_terms:\n",
    "        tf = query_terms.count(term)\n",
    "        df = len(dictionary[term]) if term in dictionary else 0\n",
    "        idf = math.log10((N + 1) / (df + 0.5))  # Adjusted IDF for smoothing\n",
    "        tf_idf = (1 + math.log10(tf)) * idf  # Log-normalized tf-idf\n",
    "        query_weights[term] = tf_idf\n",
    "        query_length += tf_idf ** 2  # Calculate query length for normalization\n",
    "    \n",
    "    query_length = math.sqrt(query_length)  # Normalize the query vector\n",
    "    \n",
    "    # Rank documents by cosine similarity\n",
    "    scores = defaultdict(float)\n",
    "    for term, query_weight in query_weights.items():\n",
    "        if term in dictionary:\n",
    "            for docID, tf in dictionary[term]:\n",
    "                # Use log-normalized tf-idf for document weight\n",
    "                doc_weight = (1 + math.log10(tf)) * math.log10((N + 1) / (len(dictionary[term]) + 0.5))\n",
    "                scores[docID] += (query_weight * doc_weight)\n",
    "    \n",
    "    # Normalize the scores by document lengths and query length\n",
    "    for docID in scores:\n",
    "        if doc_lengths[docID] > 0 and query_length > 0:\n",
    "            scores[docID] /= (doc_lengths[docID] * query_length)\n",
    "    \n",
    "    # Apply sigmoid function to boost lower scores while keeping them between 0 and 1\n",
    "    for docID in scores:\n",
    "        scores[docID] = 2 / (1 + math.exp(-10 * scores[docID])) - 1\n",
    "    \n",
    "    # Sort by score and then by docID\n",
    "    ranked_docs = sorted(scores.items(), key=lambda x: (-x[1], x[0]))\n",
    "    \n",
    "    # Output top 10 results with actual filenames\n",
    "    return [(docID_to_filename[docID], score) for docID, score in ranked_docs[:10]]\n",
    "\n",
    "# Main Function\n",
    "def main():\n",
    "    corpus_path = 'C:\\\\Users\\\\Himanish\\\\Desktop\\\\IR Assignment 2\\\\Corpus'\n",
    "    index_corpus(corpus_path)\n",
    "    \n",
    "    # Ask user for input query\n",
    "    query = input(\"Enter your search query: \")\n",
    "    \n",
    "    # Process the query and get results\n",
    "    results = process_query(query)\n",
    "    \n",
    "    # Display the results\n",
    "    print(\"\\nTop 10 relevant documents:\")\n",
    "    for doc, score in results:\n",
    "        print(f\"{doc}: {score:.15f}\")  # Displaying scores with higher precision for better comparison\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb8dc68-3619-4c49-93b0-f2fcbacf1fc5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
